### General settings.
## The name of singer
spk: "namine_ritsu"

## exp tag(for managing experiments)
tag:

## Directory of Unzipped singing voice database
# PLEASE CHANGE THE PATH BASED ON YOUR ENVIRONMENT
db_root: "~/Documents/「波音リツ」歌声データベースVer2.0.2"

## Output directory
# All the generated labels, intermediate files, and segmented wav files
# will be saved in the following directory
out_dir: "./data"

## Songs to be excluded from training.
exclude_songs: []

### Utaupy related settings.
## Utaupy table path
# This singing voice database contains the unvoiced vowels "I" and "U".
# To enable the unvoiced vowels, modified version of sinsy dictionary files
# are needed.
utaupy_table_path: "../../_common/no2/utaupy/kana2phonemes_002_oto2lab.table"

## HTS-style question used for extracting musical/linguistic context from musicxml files
question_path: "../../_common/hed/jp_dev_latest.hed"

### Data preparation related settings.
## Song segmentation by silence durations.
# TODO: would be better to split songs by phrasal information in the musical scores
# Split song by silences (in sec)
segmentation_threshold: 0.1
# Min duration for a segment
# note: there could be some exceptions (e.g., the last segment of a song)
segment_min_duration: 5.0
# Force split segments if long silence is found regardless of min_duration
force_split_threshold: 5.0
# Offset correction
# If True, offset is computed in an entire song
# otherwise offset is computed for each segment
global_offset_correction: False
offset_correction_threshold: 0.01
# Time-lag constraints to filter outliers
timelag_allowed_range: [-20, 19]
timelag_allowed_range_rest: [-40, 39]

suppress_start_end_pau: True
start_end_pau_suppression_ratio: 0.2

# Audio sampling rate
# CAUTION: Changing sample_rate may affect the dimension number of acoustic features.
# DO NOT CHANGE this unless you know the relationship between the dim of bap and sample_rate.
sample_rate: 48000

gain_normalize: False

###########################################################
#                FEATURE EXTRACTION SETTING               #
###########################################################

timelag_features: defaults
duration_features: defaults
acoustic_features: nnsvs_contrib_static_only

# Parameter trajectory smoothing
# Ref: The NAIST Text-to-Speech System for the Blizzard Challenge 2015
trajectory_smoothing: false
trajectory_smoothing_cutoff: 50

###########################################################
#                TRAINING SETTING                         #
###########################################################

# Models
# To customize, put your config or change ones in
# conf/train/{timelag,duration,acoustic}/ and
# specify the config name below
# NOTE: *_model: model definition, *_train: general train configs,
# *_data: data configs (e.g., batch size)

timelag_model: timelag_vp_mdn
timelag_train: myconfig
timelag_data: myconfig

duration_model: duration_vp_mdn
duration_train: myconfig
duration_data: myconfig

acoustic_model: acoustic_nnsvs_world_multi_ar_f0_diff_mgcbap
acoustic_train: diffusion
acoustic_data: world_diffusion

postfilter_model: postfilter_mgc
postfilter_train: mgc
postfilter_data: myconfig

# Pretrained model dir (leave empty to disable)
pretrained_expdir:

# Advanced settings for hyperparameter search with Hydra and Optuna.
# https://hydra.cc/docs/plugins/optuna_sweeper/
# NOTE: Don't use spaces for each search space configuration.
# OK: data.batch_size=range(1,16)
# NG: data.batch_size=range(1, 16)
# Example 1: data.batch_size=range(1,16) model.netG.hidden_dim=choice(32,64,128)
# Example 2: train.optim.optimizer.params.lr=interval(0.0001,0.01)
timelag_hydra_optuna_sweeper_args:
timelag_hydra_optuna_sweeper_n_trials: 100
duration_hydra_optuna_sweeper_args:
duration_hydra_optuna_sweeper_n_trials: 100
acoustic_hydra_optuna_sweeper_args:
acoustic_hydra_optuna_sweeper_n_trials: 100

###########################################################
#                SYNTHESIS SETTING                        #
###########################################################
# conf/synthesis/synthesis/${synthesis}
# If you use uSFGAN or SiFi-GAN, please set `world_gv_usfgan`
synthesis: world_gv

# latest.pth or best.pth
timelag_eval_checkpoint: latest.pth
duration_eval_checkpoint: latest.pth
acoustic_eval_checkpoint: latest.pth
postfilter_eval_checkpoint: latest.pth

###########################################################
#                VOCODER SETTING                          #
###########################################################

# NOTE: conf/parallel_wavegan/${vocoder_model}.yaml must exist.
vocoder_model:
# Pretrained checkpoint path for the vocoder model
# NOTE: if you want to try fine-tuning, please specify the path here
pretrained_vocoder_checkpoint:
# absolute/relative path to the checkpoint
# NOTE: the checkpoint is used for synthesis and packing
# This doesn't have any effect on training
vocoder_eval_checkpoint:
